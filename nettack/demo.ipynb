{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravsa\\anaconda3\\envs\\CIS-700_Midterm\\lib\\site-packages\\scipy\\__init__.py:140: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.16.1)\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ravsa\\Downloads\\SU\\Spring 2021\\Midterm_Spring_2021\\nettack\\nettack\\GCN.py:6: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from nettack import utils, GCN\n",
    "from nettack import nettack as ntk\n",
    "import numpy as np\n",
    "gpu_id = None # set this to your desired GPU ID if you want to use GPU computations (only for the GCN/surrogate training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network, basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_A_obs, _X_obs, _z_obs = utils.load_npz('data/citeseer.npz')\n",
    "_A_obs = _A_obs + _A_obs.T\n",
    "_A_obs[_A_obs > 1] = 1\n",
    "lcc = utils.largest_connected_components(_A_obs)\n",
    "\n",
    "_A_obs = _A_obs[lcc][:,lcc]\n",
    "\n",
    "assert np.abs(_A_obs - _A_obs.T).sum() == 0, \"Input graph is not symmetric\"\n",
    "assert _A_obs.max() == 1 and len(np.unique(_A_obs[_A_obs.nonzero()].A1)) == 1, \"Graph must be unweighted\"\n",
    "assert _A_obs.sum(0).A1.min() > 0, \"Graph contains singleton nodes\"\n",
    "\n",
    "_X_obs = _X_obs[lcc].astype('float32')\n",
    "_z_obs = _z_obs[lcc]\n",
    "_N = _A_obs.shape[0]\n",
    "_K = _z_obs.max()+1\n",
    "_Z_obs = np.eye(_K)[_z_obs]\n",
    "_An = utils.preprocess_graph(_A_obs)\n",
    "sizes = [16, _K]\n",
    "degrees = _A_obs.sum(0).A1\n",
    "\n",
    "seed = 15\n",
    "unlabeled_share = 0.8\n",
    "val_share = 0.1\n",
    "train_share = 1 - unlabeled_share - val_share\n",
    "np.random.seed(seed)\n",
    "\n",
    "split_train, split_val, split_unlabeled = utils.train_val_test_split_tabular(np.arange(_N),\n",
    "                                                                       train_size=train_share,\n",
    "                                                                       val_size=val_share,\n",
    "                                                                       test_size=unlabeled_share,\n",
    "                                                                       stratify=_z_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the node to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 0 # node to attack\n",
    "assert u in split_unlabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train surrogate model (i.e. GCN without nonlinear activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_model = GCN.GCN(sizes, _An, _X_obs, with_relu=False, name=\"surrogate\", gpu_id=gpu_id)\n",
    "surrogate_model.train(split_train, split_val, _Z_obs)\n",
    "W1 =surrogate_model.W1.eval(session=surrogate_model.session)\n",
    "W2 =surrogate_model.W2.eval(session=surrogate_model.session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Nettack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettack = ntk.Nettack(_A_obs, _X_obs, _z_obs, W1, W2, u, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_attack = True\n",
    "n_influencers = 1 if direct_attack else 5\n",
    "n_perturbations = int(degrees[u]) # How many perturbations to perform. Default: Degree of the node\n",
    "perturb_features = True\n",
    "perturb_structure = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poison the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettack.reset()\n",
    "nettack.attack_surrogate(n_perturbations, perturb_structure=perturb_structure, perturb_features=perturb_features, direct=direct_attack, n_influencers=n_influencers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nettack.structure_perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nettack.feature_perturbations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GCN without perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_iters=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_margins_clean = []\n",
    "class_distrs_clean = []\n",
    "gcn_before = GCN.GCN(sizes, _An, _X_obs, \"gcn_orig\", gpu_id=gpu_id)\n",
    "for _ in range(retrain_iters):\n",
    "    print(\"... {}/{} \".format(_+1, retrain_iters))\n",
    "    gcn_before.train(split_train, split_val, _Z_obs)\n",
    "    probs_before_attack = gcn_before.predictions.eval(session=gcn_before.session,feed_dict={gcn_before.node_ids: [nettack.u]})[0]\n",
    "    class_distrs_clean.append(probs_before_attack)\n",
    "    best_second_class_before = (probs_before_attack - 1000*_Z_obs[nettack.u]).argmax()\n",
    "    margin_before = probs_before_attack[_z_obs[nettack.u]] - probs_before_attack[best_second_class_before]\n",
    "    classification_margins_clean.append(margin_before)\n",
    "class_distrs_clean = np.array(class_distrs_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GCN with perturbations\n",
    "(insert your favorite node classification algorithm here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_margins_corrupted = []\n",
    "class_distrs_retrain = []\n",
    "gcn_retrain = GCN.GCN(sizes, nettack.adj_preprocessed, nettack.X_obs.tocsr(), \"gcn_retrain\", gpu_id=gpu_id)\n",
    "for _ in range(retrain_iters):\n",
    "    print(\"... {}/{} \".format(_+1, retrain_iters))\n",
    "    gcn_retrain.train(split_train, split_val, _Z_obs)\n",
    "    probs_after_attack = gcn_retrain.predictions.eval(session=gcn_retrain.session,feed_dict={gcn_retrain.node_ids: [nettack.u]})[0]\n",
    "    best_second_class_after = (probs_after_attack - 1000*_Z_obs[nettack.u]).argmax()\n",
    "    margin_after = probs_after_attack[_z_obs[nettack.u]] - probs_after_attack[best_second_class_after]\n",
    "    class_distrs_retrain.append(probs_after_attack)\n",
    "    classification_margins_corrupted.append(margin_after)\n",
    "class_distrs_retrain = np.array(class_distrs_retrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xlabel(ix, correct):\n",
    "    if ix==correct:\n",
    "        return \"Class {}\\n(correct)\".format(ix)\n",
    "    return \"Class {}\".format(ix)\n",
    "\n",
    "figure = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "center_ixs_clean = []\n",
    "for ix, block in enumerate(class_distrs_clean.T):\n",
    "    x_ixs= np.arange(len(block)) + ix*(len(block)+2)\n",
    "    center_ixs_clean.append(np.mean(x_ixs))\n",
    "    color = '#555555'\n",
    "    if ix == nettack.label_u:\n",
    "        color = 'darkgreen'\n",
    "    plt.bar(x_ixs, block, color=color)\n",
    "\n",
    "ax=plt.gca()\n",
    "plt.ylim((-.05, 1.05))\n",
    "plt.ylabel(\"Predicted probability\")\n",
    "ax.set_xticks(center_ixs_clean)\n",
    "ax.set_xticklabels([make_xlabel(k, nettack.label_u) for k in range(_K)])\n",
    "ax.set_title(\"Predicted class probabilities for node {} on clean data\\n({} re-trainings)\".format(nettack.u, retrain_iters))\n",
    "\n",
    "fig = plt.subplot(1, 2, 2)\n",
    "center_ixs_retrain = []\n",
    "for ix, block in enumerate(class_distrs_retrain.T):\n",
    "    x_ixs= np.arange(len(block)) + ix*(len(block)+2)\n",
    "    center_ixs_retrain.append(np.mean(x_ixs))\n",
    "    color = '#555555'\n",
    "    if ix == nettack.label_u:\n",
    "        color = 'darkgreen'\n",
    "    plt.bar(x_ixs, block, color=color)\n",
    "\n",
    "\n",
    "ax=plt.gca()\n",
    "plt.ylim((-.05, 1.05))\n",
    "ax.set_xticks(center_ixs_retrain)\n",
    "ax.set_xticklabels([make_xlabel(k, nettack.label_u) for k in range(_K)])\n",
    "ax.set_title(\"Predicted class probabilities for node {} after {} perturbations\\n({} re-trainings)\".format(nettack.u, n_perturbations, retrain_iters))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
